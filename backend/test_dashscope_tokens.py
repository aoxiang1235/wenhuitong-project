#!/usr/bin/env python3
"""
æµ‹è¯•dashscope tokenæ’ä»¶çš„å‡†ç¡®æ€§
"""
import os
import sys
import django

# è®¾ç½®Djangoç¯å¢ƒ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')
django.setup()

def test_dashscope_tokenizer():
    """æµ‹è¯•dashscopeæœ¬åœ°åˆ†è¯å™¨"""
    try:
        from dashscope.tokenizers import get_tokenizer
        
        print("ğŸ” æµ‹è¯•dashscopeæœ¬åœ°åˆ†è¯å™¨")
        print("=" * 50)
        
        # è·å–åˆ†è¯å™¨
        tokenizer = get_tokenizer('qwen-turbo')
        
        # æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "ä½ å¥½ä¸–ç•Œ",
            "Hello World",
            "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«ä¸­è‹±æ–‡æ··åˆå†…å®¹ã€‚This is a test text with mixed Chinese and English content.",
            "é€šä¹‰åƒé—®æ˜¯ä¸€ä¸ªå¼ºå¤§çš„AIæ¨¡å‹",
            "Qwen is a powerful AI model"
        ]
        
        for text in test_texts:
            try:
                tokens = tokenizer.encode(text)
                token_count = len(tokens)
                print(f"âœ… æ–‡æœ¬: {text[:30]}...")
                print(f"   Tokenæ•°é‡: {token_count}")
                print(f"   å­—ç¬¦æ•°: {len(text)}")
                print(f"   æ¯”ä¾‹: {token_count/len(text):.2f} tokens/char")
                print(f"   Tokenåˆ—è¡¨: {tokens[:10]}...")  # æ˜¾ç¤ºå‰10ä¸ªtoken
            except Exception as e:
                print(f"âŒ æ–‡æœ¬: {text[:30]}...")
                print(f"   é”™è¯¯: {str(e)}")
            
            print("-" * 30)
            
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥dashscope.tokenizers: {e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…dashscope: pip install dashscope")

def test_dashscope_api():
    """æµ‹è¯•dashscope APIï¼ˆéœ€è¦API keyï¼‰"""
    try:
        from dashscope import Tokenization
        
        print("ğŸ” æµ‹è¯•dashscope API Tokenization")
        print("=" * 50)
        
        # æµ‹è¯•æ–‡æœ¬
        test_text = "ä½ å¥½ä¸–ç•Œ"
        
        try:
            response = Tokenization.call(
                model='qwen-turbo',
                prompt=test_text
            )
            
            if response.status_code == 200:
                token_count = response.output.get('token_count', 0)
                print(f"âœ… APIè°ƒç”¨æˆåŠŸ")
                print(f"   æ–‡æœ¬: {test_text}")
                print(f"   Tokenæ•°é‡: {token_count}")
                print(f"   å“åº”: {response.output}")
            else:
                print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.message}")
                
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            print("å¯èƒ½éœ€è¦è®¾ç½®API keyæˆ–ç½‘ç»œè¿æ¥é—®é¢˜")
            
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥dashscope: {e}")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•dashscope tokenæ’ä»¶")
    print()
    
    # æµ‹è¯•æœ¬åœ°åˆ†è¯å™¨
    test_dashscope_tokenizer()
    print()
    
    # æµ‹è¯•API
    test_dashscope_api()
    
    print("âœ… æµ‹è¯•å®Œæˆ") 